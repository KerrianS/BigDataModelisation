# üöÄ Plateforme Big Data : Pipeline ETL pour Cryptomonnaies

[![Big Data Platform CI/CD](https://github.com/KerrianS/BigDataModelisation/actions/workflows/ci.yml/badge.svg)](https://github.com/KerrianS/BigDataModelisation/actions/workflows/ci.yml)

## ‚úçÔ∏è Auteurs
**SAL√ÑUN Kerrian** & **Rapha√´l DIMECK** (IMT Nord Europe - F√©vrier 2026)

---

## üìñ Pr√©sentation du Projet
Ce projet impl√©mente une plateforme **Big Data** de bout en bout pour l'ingestion, le traitement et la visualisation de donn√©es de march√© en temps r√©el pour le **top 100 des cryptomonnaies**. 
> **Security**: This project uses GitHub Secrets for CI/CD credentials. See [docs/GITHUB_SECRETS.md](docs/GITHUB_SECRETS.md) for configuration instructions.

## Prerequisites

L'architecture repose sur un mod√®le **Lambda/Lakehouse** moderne garantissant :
- **Persistance** des donn√©es brutes (Data Lake - MongoDB).
- **Vitesse** du traitement en streaming (Kafka + Spark).
- **Puissance** des requ√™tes analytiques (Data Warehouse - PostgreSQL).
- **Observabilit√©** totale (Grafana + Prometheus + Loki + Alerting).

---

## üèóÔ∏è Architecture Globale

```mermaid
graph TB
    subgraph "Sources de Donn√©es"
        API[CoinGecko API<br/>REST API]
    end
    
    subgraph "Couche d'Ingestion (Bronze)"
        AIRFLOW[Airflow Scheduler<br/>Orchestration ETL]
    end
    
    subgraph "Couche de Stockage"
        MONGO[(MongoDB<br/>Data Lake<br/>Donn√©es Brutes)]
        POSTGRES[(PostgreSQL<br/>Data Warehouse<br/>Donn√©es Structur√©es)]
    end
    
    subgraph "Couche de Traitement (Silver)"
        KAFKA[Kafka<br/>Message Broker]
        SPARK[Spark Streaming<br/>Transformation]
        PRODUCER[Mongo-to-Kafka<br/>CDC / Polling]
    end
    
    subgraph "Visualisation & Alerting"
        GRAFANA[Grafana<br/>Dashboards & Alerts]
        ALERTMAN[Alertmanager<br/>Notifications]
    end
    
    subgraph "Monitoring & Observabilit√©"
        PROM[Prometheus<br/>M√©triques]
        LOKI[Loki<br/>Logs]
        PROMTAIL[Promtail<br/>Collecteur de Logs]
    end
    
    API -->|HTTP GET| AIRFLOW
    AIRFLOW -->|Insert JSON| MONGO
    MONGO -->|Stream| PRODUCER
    PRODUCER -->|Publish| KAFKA
    KAFKA -->|Consume| SPARK
    SPARK -->|Write JDBC| POSTGRES
    POSTGRES -->|SQL Query| GRAFANA
    PROM -.->|Scrape| ALERTMAN
    ALERTMAN -.->|Notify| GRAFANA
    AIRFLOW -.->|Logs| PROMTAIL
    PROMTAIL -.->|Push| LOKI
    LOKI -.->|Analyze| GRAFANA
    PROM -.->|Metrics| GRAFANA
```

---

## üõ†Ô∏è Stack Technique & R√¥les

| Composant | Technologie | R√¥le Technique |
| :--- | :--- | :--- |
| **Orchestrateur** | **Airflow** | Planification des t√¢ches (DAGs) et appels API CoinGecko toutes les 3 min. |
| **Data Lake** | **MongoDB** | Stockage immuable des documents JSON bruts originaux. |
| **Bus d'√âv√©nements** | **Kafka** | D√©couplage des services et buffer de streaming haute performance. |
| **Moteur SQL** | **Spark** | Transformation complexe, nettoyage et typage des donn√©es en micro-batches. |
| **Warehouse** | **PostgreSQL** | Stockage structur√© et index√© pour la visualisation rapide. |
| **Observabilit√©** | **Prometheus** | Collecte des m√©triques syst√®me (CPU, RAM, Uptime). |
| **Gestion Logs** | **Loki + Promtail** | Centralisation et indexation de tous les logs containers. |
| **Visualisation** | **Grafana** | Dashboards temps r√©el et gestionnaire centralis√© d'alertes. |
| **Alerting** | **Alertmanager** | Groupement et routage des alertes vers les terminaux finaux. |

---

## üö® Syst√®me d'Alerting (Nouveau)

La plateforme int√®gre d√©sormais un syst√®me d'alertes √† deux niveaux :

### 1. Alertes d'Infrastructure (via Prometheus & Alertmanager)
- **ServiceDown** : D√©clench√© si un container (Airflow, Spark, Kafka) ne r√©pond plus pendant plus d'une minute.
- **IngestionLagging** : D√©tecte si le job Airflow n'est plus visible par le syst√®me de monitoring.

### 2. Alertes M√©tier & Pipeline (via Grafana Unified Alerting)
- **Bitcoin Price Crash** : Alerte critique d√©clench√©e si le cours du Bitcoin varie de plus de **-10%** sur 24h.
- **Ingestion Pipeline Stalled** : Alerte de s√©curit√© activ√©e si aucune nouvelle donn√©e n'est ins√©r√©e dans PostgreSQL pendant plus de **10 minutes** (signe d'un blocage Spark ou Kafka).

---

## üìã Pr√©requis & Installation

### Pr√©requis
- **Docker** & **Docker Compose** install√©s.
- Au moins **8 Go de RAM** allou√©s √† Docker pour supporter Spark et Kafka simultan√©ment.

### Lancement Rapide
1. **Configurer l'environnement** :
   ```bash
   cp .env.example .env
   # Modifier les credentials si n√©cessaire
   ```
2. **D√©marrer la stack** :
   ```bash
   docker-compose up -d
   ```
3. **V√©rifier l'√©tat** :
   ```bash
   docker-compose ps
   ```

---

## üîó Acc√®s aux Services

| Service | URL | Identifiants |
| :--- | :--- | :--- |
| **Airflow UI** | [http://localhost:8080](http://localhost:8080) | `airflow` / `airflow` |
| **Grafana** | [http://localhost:3000](http://localhost:3000) | `admin` / `admin` |
| **Prometheus** | [http://localhost:9090](http://localhost:9090) | - |
| **Alertmanager** | [http://localhost:9093](http://localhost:9093) | - |
| **Spark Master** | [http://localhost:8081](http://localhost:8081) | - |

---

## üß™ Maintenance & Tests

### Scripts Utilitaires (`/src`)
- `check_datalake.py` : Compare les donn√©es dans MongoDB et Postgres.
- `manual_ingestion.py` : Force un appel API imm√©diat sans attendre le scheduler Airflow.
- `test_mongo.py` : V√©rifie la connectivit√© au Data Lake.

### Commandes Utiles
```bash
# Red√©marrer uniquement le pipeline de traitement
docker-compose restart spark-streaming

# Consulter les logs d'ingestion
docker-compose logs -f airflow-scheduler

# Simuler un crash pour tester les alertes
docker-compose stop spark-worker
```

### Acc√®s direct aux bases de donn√©es
- **Postgres** : `docker exec -it bigdatamodelisation-postgres-1 psql -U airflow -d airflow`
- **MongoDB** : `docker exec -it bigdatamodelisation-mongo-1 mongosh --username admin --password admin`

---

## üîÆ Roadmap & Am√©liorations Futures
- [ ] **Data Quality** : Ajout de Great Expectations pour valider les donn√©es en sortie de Spark.
- [ ] **Diversification** : Int√©gration de l'API Binance et Coinbase pour comparer les prix.
- [ ] **IA** : Impl√©mentation d'un mod√®le de pr√©diction via Spark MLlib.
- [ ] **D√©ploiement** : Migration de l'architecture vers Kubernetes (K8s) avec Helm Charts.

---
**Note sur la s√©curit√©** : Toutes les communications entre composants se font via le r√©seau Docker s√©curis√© interne. Pour une exposition publique, l'utilisation d'un Reverse Proxy (Nginx/Traefik) avec HTTPS est imp√©rative.